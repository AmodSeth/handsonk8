{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Hands-on Kubernetes Notes","text":"<p>Welcome to my Kubernetes practice notes. Everything here is organized section-wise with simple explanations and examples.</p>"},{"location":"#sections","title":"\ud83d\udcd8 Sections","text":"<ul> <li>Section 1 \u2014 Installation</li> <li>Section 2 \u2014 Pods</li> <li>Section 3 \u2014 Services</li> <li>Section 4 \u2014 ReplicaSets</li> <li>Section 5 \u2014 Deployments</li> <li>Section 6 - networking</li> </ul>"},{"location":"Section_1_installation/","title":"Section 1 - Installation","text":""},{"location":"Section_1_installation/#remarks","title":"Remarks","text":"<p>--&gt; client version and server version should be the same </p> <pre><code>    brew install fish\n</code></pre>"},{"location":"Section_1_installation/#add-this-is-in-bashrc","title":"Add this is in bashrc","text":"<pre><code>    alias k = 'kubectl'\n</code></pre>"},{"location":"Section_2_pods/","title":"Pods","text":"<p>Pods are just the wrappers for containers</p> <p>Generally its always one container per pod , but genrally few times its more as a helper container like ingesting logs or metrics of the main container. eg: </p>"},{"location":"Section_2_pods/#writing-a-pod-spec","title":"Writing a Pod Spec","text":"<p>apiVersion: v1 kind: Pod metadata:     name: myapp-pod     labels:         app: myapp spec:     containers:     - name: nginx</p>"},{"location":"Section_2_pods/#writing-pod-file-for-the-course","title":"writing pod file for the course","text":"<p>apiVersion: v1 kind: Pod metadata:     name: webapp spec:      containers:     - name: webapp       image: richardchesterwood/k8s-fleetman-webapp-angular:release0</p>"},{"location":"Section_2_pods/#error-faced-pod-status-crashloopbackoff","title":"Error faced  Pod status: CrashLoopBackOff","text":"<p>Kubernetes starts your container, it crashes/exits, and Kubelet keeps trying to restart it, but each time it fails again, so Kubernetes backs off (waits longer and longer) before the next restart.</p> <p>RCA - Got this error coz the image didn't supported the same architecture.</p> <p>Solution: got into the docker hub of it and found the right multi arch image and updated the pod file.</p>"},{"location":"Section_2_pods/#exec-into-the-pod","title":"Exec into the pod","text":"<p>Since its a single container pod we can exec into it using below command Note: use the Help if not sure about the command</p> <pre><code>k exec -it &lt;pod Name&gt; -- Command (eg: /bin/bash)\n</code></pre> <pre><code>k exec -it webapp -- Date\nk exec -it webapp -- bash\n</code></pre>"},{"location":"Section_2_pods/#get-the-pods-with-labels","title":"Get the pods with labels","text":"<pre><code>k get po --show-labels\nk get po -l app=webapp # -l is for label filtering\n</code></pre>"},{"location":"Section_2_pods/#to-delete-all-the-pods","title":"to delete all the pods","text":"<pre><code>k delete po --all\n</code></pre>"},{"location":"Section_2_pods/#concept-of-labels-and-selectors","title":"Concept of labels and Selectors","text":"<p>Labels are key/value pairs that are attached to objects, such as pods. Labels are intended to be used to specify identifying attributes of objects that are meaningful and relevant to users.</p> <p>Selectors are used to filter a list of resources based on their labels. They allow users to select a subset of resources that match certain criteria.</p>"},{"location":"Section_3_services/","title":"Services","text":"<p>--&gt; service is a long running object with long stable running port.</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n    #Unique key of the service\n    name: flettman-webapp-service\nspec:\n    # This defines which pods are gonna be represented by this service\n    # The service becomes a endpoint to access the pods / or for other # # services to access the pods\n    selector:\n        app: webapp\n\n    ports:\n    - name: http\n      protocol: TCP\n      port: 80            # Port on which the service is exposed\n      targetPort: 80     # Port on the pod to which the traffic is \n      nodePort: 30080  # Port on each node to expose the service (only for NodePort type)\n\n    type: NodePort #second P is capital\n</code></pre>"},{"location":"Section_3_services/#type-of-services","title":"Type of services","text":"<ul> <li> <p>ClusterIP - default type - only accessible within the cluster</p> </li> <li> <p>NodePort - accessible outside the cluster using : <pre><code>    Nodeport has some conditions\n    It must be greater than 30000 and less than 32767\n</code></pre>"},{"location":"Section_3_services/#excersise-11-deploying-a-queue-service","title":"Excersise 1.1 - Deploying a queue service","text":"<ol> <li>Deploy the image</li> <li>Port 8161 is the admin console</li> <li>Expose this to a browser using NodePort service 30010</li> </ol> <p>```</p>"},{"location":"Section_3_services/#writing-the-pods-file","title":"writing the pods file","text":"<p>apiVersion: v1 kind: Pod metadata:     name: fleetman-queue     labels:         app: queue spec:     containers:     - name: queue-container       image:        port: 8161       targetPort: 8161</p>"},{"location":"Section_4_replicasets/","title":"Replica Set","text":""},{"location":"Section_4_replicasets/#replicaset-in-kubernetes-or-rs","title":"replicaSet in kubernetes or rs","text":"<ol> <li>It is an extra piece of configuration to ensure that the Kubernetes pods are always running for the desired number of replicas.</li> </ol>"},{"location":"Section_4_replicasets/#points-to-remember","title":"Points to remember","text":"<ul> <li>ReplicaSet is a higher-level abstraction that manages multiple instances of a pod.</li> <li>it has 3 new keys<ul> <li>template: pod template that defines the pod's configuration (inside spec)</li> <li>selector: label selector to identify the pods managed by the ReplicaSet (match labels for which we are applying pod)</li> <li>replicas: number of desired pod instances</li> </ul> </li> </ul> <pre><code>apiVersion: apps/v1\nkind: ReplicaSet\nmetadata: \n    name: webapp\nspec:\n    replicas: 1\n    selector:\n        matchLabels:\n            app: webapp #this  should match\n    template:\n        metadata:\n            labels:\n                app: webapp #this  should match\n        spec:\n            containers:\n            - name: webapp\n              image: nginx\n</code></pre>"},{"location":"Section_4_replicasets/#note","title":"Note","text":"<p>Pods created by ReplicaSet will have a unique suffix added to their names for identification. like webapp-xxxxx</p>"},{"location":"Section_4_replicasets/#testing-it","title":"Testing it","text":"<ol> <li>I deleted all the pods using k delete po --all</li> <li>It swapped to 0/1 pods</li> <li>It spawned the new pods with new suffix within seconds</li> </ol>"},{"location":"Section_5_deployments/","title":"Deployments","text":"<ul> <li>A deployment is a Kubernetes resource that provides declarative updates to applications.</li> <li>It manages the creation and scaling of Pods, ensuring that the desired number of replicas are running at any given time.</li> <li>Deployments are commonly used for stateless applications, allowing for easy updates and rollbacks.</li> <li>Similar to ReplicaSet but with rolling updates and rollback, providing zero downtime for application deployments.</li> </ul>"},{"location":"Section_5_deployments/#nothing-but-the-glorified-replicaset","title":"Nothing but the glorified ReplicaSet","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata: \n    name: webapp\nspec:\n    replicas: 1\n    selector:\n        matchLabels:\n            app: webapp # this should match\n    template:\n        metadata:\n            labels:\n                app: webapp # this should match\n        spec:\n            containers:\n            - name: webapp\n              image: nginx\n</code></pre>"},{"location":"Section_5_deployments/#revision","title":"Revision","text":"<ul> <li>Every time you change the Pod template inside a Deployment, Kubernetes creates a new ReplicaSet, and that creates a new revision.</li> <li>Triggers a new revision:</li> <li>Changing image (nginx:1.19 \u2192 nginx:1.20)</li> <li>Changing env vars</li> <li>Changing labels in pod template</li> <li>Changing resource limits</li> <li>Does NOT trigger revision:</li> <li>Scaling replicas count</li> <li>Changing annotations on Deployment metadata</li> </ul>"},{"location":"Section_5_deployments/#rollout","title":"Rollout","text":"<p>Rollout is how Kubernetes replaces old Pods with new Pods during a Deployment update.</p>"},{"location":"Section_6_networkandservicediscovery/","title":"Networking and Service Discovery","text":""},{"location":"Section_6_networkandservicediscovery/#namespaces","title":"Namespaces","text":"<p>they are the logical partitions within a cluster. They provide a way to divide cluster resources between multiple users  - To get the list of all available namespaces <pre><code>k get ns\n</code></pre> - To get the details of a specific namespace <pre><code>k get pods -n &lt;namespace-name&gt;\n</code></pre></p>"},{"location":"Section_6_networkandservicediscovery/#services","title":"Services","text":"<ul> <li>Creating a db mysql container and service <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: mysql\n  labels:\n    app: mysql\nspec:\n  containers:\n    - name: mysql-pod\n      image: mysql:8.0.44\n      env:\n      - name: MYSQL_ROOT_PASSWORD\n        value: password\n      - name: MYSQL_DATABASE\n        value: fleetman\n\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: database\nspec:\n  selector:\n    app: mysql\n  ports:\n    - protocol: TCP\n      port: 3306\n\n  type: ClusterIP\n</code></pre></li> </ul>"},{"location":"Section_6_networkandservicediscovery/#networking-models","title":"Networking Models","text":"<ul> <li>check relolve.conf file inside the pod <pre><code>k exec -it &lt;pod-name&gt; -- cat /etc/resolv.conf\n</code></pre></li> </ul>"},{"location":"kubernetes-learning-index/","title":"Kubernetes Learning","text":"<p>Core Kubernetes concepts and hands-on practice.</p>"},{"location":"kubernetes-learning-index/#sections","title":"\ud83d\udcd8 Sections","text":"<ul> <li>Section 1 \u2014 Installation</li> <li>Section 2 \u2014 Pods</li> <li>Section 3 \u2014 Services</li> <li>Section 4 \u2014 ReplicaSets</li> <li>Section 5 \u2014 Deployments</li> <li>Section 6 \u2014 Networking</li> </ul>"},{"location":"Troubleshooting/","title":"Troubleshooting Guide","text":"<p>Common Kubernetes issues and their solutions.</p>"},{"location":"Troubleshooting/#issues","title":"\ud83d\udcd8 Issues","text":"<ul> <li>Resource name may not be empty</li> <li>ReplicaSet won't touch existing pods</li> <li>Why Pod didn't come back</li> </ul>"},{"location":"Troubleshooting/Replicaset_wont_touch_me/","title":"ReplicaSet Issues","text":""},{"location":"Troubleshooting/Replicaset_wont_touch_me/#why-did-you-have-to-delete-the-pod-manually","title":"Why did you have to delete the Pod manually?","text":"<p>Sequence you described:</p> <p>ReplicaSet created with template using image tag ...release0-5. \u2192 Pod comes up fine.</p> <p>You delete that Pod with kubectl delete pod . \u2192 ReplicaSet notices it has 0/1 Pods and creates a new Pod from the same template \u2705 <p>You break the template (wrong image name). \u2192 New Pod is created, but it goes to ImagePullBackOff.</p> <p>You fix the image name in the ReplicaSet YAML and run kubectl apply -f workload.yaml. \u2192 ReplicaSet object is updated, but the bad Pod is still there.</p> <p>ReplicaSet sees: \u201cI should have 1 replica; I already have 1 Pod (even if it\u2019s failing), so my job is done.\u201d \u2192 It does not delete or recreate that Pod.</p> <p>You manually delete the Pod. \u2192 ReplicaSet now sees 0/1 Pods and creates a new one \u2014 this time using the corrected template, so it works.</p> <p>\ud83d\udc49 Key idea: A ReplicaSet does not update existing Pods when you change the template. It only ensures the count of Pods. If the count is satisfied, it won\u2019t touch running / failing Pods.</p> <p>To force new Pods with the updated template you must either:</p> <p>delete the old Pods:</p> <p>kubectl delete pod"},{"location":"Troubleshooting/Replicaset_wont_touch_me/#or-all-pods-of-that-rs","title":"or all pods of that RS:","text":"<p>kubectl delete pods -l app=webapp</p> <p>OR change spec.replicas (e.g. scale to 0 then back to 1).</p> <p>For automatic rollouts when the template changes, Kubernetes uses a Deployment, which internally creates new ReplicaSets and gradually replaces Pods. That\u2019s why for \u201cnormal apps\u201d we use Deployment instead of raw ReplicaSet</p>"},{"location":"Troubleshooting/Resource_name_can%27t_be_empty/","title":"RCA: \u201cresource name may not be empty\u201d","text":""},{"location":"Troubleshooting/Resource_name_can%27t_be_empty/#issue","title":"Issue:","text":"<p><code>kubectl apply -f &lt;file&gt;</code> returned: <pre><code>error: resource name may not be empty.\n</code></pre></p>"},{"location":"Troubleshooting/Resource_name_can%27t_be_empty/#root-cause","title":"Root Cause:","text":"<p>The metadata field in the YAML manifest was misspelled. Because metadata was incorrect, Kubernetes could not read <code>metadata.name</code>, resulting in an empty resource name.</p>"},{"location":"Troubleshooting/Resource_name_can%27t_be_empty/#how-the-issue-was-identified","title":"How the issue was identified:","text":"<ul> <li>The error referenced <code>Resource=pods</code>, meaning Kubernetes parsed the file as a Pod manifest.</li> <li>Pods require <code>metadata.name</code>.</li> <li>The error persisted even after renaming the file, which pointed to malformed YAML rather than content type.</li> <li>This strongly suggested Kubernetes could not find <code>metadata.name</code>, which typically happens when <code>metadata:</code> is misspelled or incorrectly indented.</li> <li>You confirmed that <code>metadata</code> was indeed misspelled.</li> </ul>"},{"location":"Troubleshooting/Resource_name_can%27t_be_empty/#impact","title":"Impact:","text":"<ul> <li>Kubernetes was unable to create or update the resource.</li> <li>Deployment was blocked until YAML was corrected.</li> </ul>"},{"location":"Troubleshooting/Resource_name_can%27t_be_empty/#fix","title":"Fix:","text":"<ul> <li>Corrected the spelling of <code>metadata:</code> and ensured a valid <code>metadata.name</code> exists.</li> </ul>"},{"location":"Troubleshooting/Resource_name_can%27t_be_empty/#prevention","title":"Prevention:","text":"<ul> <li>Use <code>kubectl apply --dry-run=client</code> to catch manifest issues early.</li> <li>Enable YAML validation in your editor (VSCode Kubernetes/YAML extensions).</li> </ul>"},{"location":"Troubleshooting/Why_Pod_didn%27t_Came_back/","title":"Why your pod didn\u2019t come back","text":"<ol> <li> <p>The pod labels do not match the Service selector</p> <ul> <li>Ensure that the labels defined in your pod specification match the selector criteria specified in your Service definition. If they do not match, the Service will not be able to route traffic to the pod.</li> </ul> <p>kubectl get svc  -o yaml <p>kubectl get pods --show-labels</p>"},{"location":"Troubleshooting/Why_Pod_didn%27t_Came_back/#change-added","title":"change added","text":""},{"location":"microservice/deploying-queue/","title":"Deploying Queue Microservice","text":"<p>``` </p>"},{"location":"minikube/","title":"Minikube","text":"<p>Local Kubernetes development environment setup and management.</p>"},{"location":"minikube/#sections","title":"\ud83d\udcd8 Sections","text":"<ul> <li>Basic Commands</li> <li>Deployment Strategies</li> </ul>"},{"location":"minikube/basic_commands/","title":"Minikube Basic Commands","text":""},{"location":"minikube/basic_commands/#to-check-the-basic-status-of-minikube","title":"To check the basic status of minikube","text":"<pre><code>minikube status\n</code></pre>"},{"location":"minikube/basic_commands/#to-start-the-minikube-cluster","title":"To start the minikube cluster","text":"<pre><code>minikube start --driver=docker\n</code></pre>"},{"location":"minikube/basic_commands/#to-stop-the-minikube-cluster","title":"To stop the minikube cluster","text":"<pre><code>minikube stop \n</code></pre>"},{"location":"minikube/Deployment-strategies/","title":"Deployment strategies in k8/ Minikube","text":""},{"location":"minikube/Deployment-strategies/#_1","title":"==================================","text":""},{"location":"minikube/Deployment-strategies/#overview","title":"Overview","text":""},{"location":"minikube/Deployment-strategies/#_2","title":"==================================","text":""},{"location":"minikube/Deployment-strategies/#sections","title":"\ud83d\udcd8 Sections","text":"<ul> <li>Release based</li> </ul>"},{"location":"minikube/Deployment-strategies/Release-based/","title":"Basic Release-based Deployment Strategy","text":"<p>A release-based deployment strategy involves deploying new versions of an application based on predefined release cycles. This approach allows for planned updates, ensuring that new features and bug fixes are introduced in a controlled manner.</p>"},{"location":"minikube/Deployment-strategies/Release-based/#baisc-way","title":"Baisc Way:","text":"<p>--&gt; Add a Label of for Release Version to the Deployment --&gt; then  Add that label to the Service's selector</p>"},{"location":"terraform/","title":"Terraform","text":"<p>Infrastructure as Code with Terraform for cloud resource management.</p>"},{"location":"terraform/#sections","title":"\ud83d\udcd8 Sections","text":"<ul> <li>Getting Started</li> <li>Basic Commands</li> <li>AWS Provider</li> </ul>"},{"location":"terraform/getting-started/","title":"Getting Started with Terraform","text":""},{"location":"terraform/getting-started/#installation","title":"Installation","text":""},{"location":"terraform/getting-started/#macos","title":"macOS","text":"<pre><code>brew install terraform\n</code></pre>"},{"location":"terraform/getting-started/#verify-installation","title":"Verify Installation","text":"<pre><code>terraform version\n</code></pre>"},{"location":"terraform/getting-started/#basic-workflow","title":"Basic Workflow","text":"<ol> <li>Write - Author infrastructure as code</li> <li>Plan - Preview changes before applying</li> <li>Apply - Provision reproducible infrastructure</li> </ol>"},{"location":"terraform/getting-started/#first-steps","title":"First Steps","text":"<pre><code>terraform init    # Initialize working directory\nterraform plan     # Create execution plan\nterraform apply    # Execute the actions proposed in plan\nterraform destroy  # Destroy managed infrastructure\n</code></pre>"}]}